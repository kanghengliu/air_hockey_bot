{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Robo Rink: Reinforcement Learning Implementation on Custom Air Hockey Game\"\n",
        "subtitle: \"DSAN 6600: Neural Nets and Deep Learning\"\n",
        "authors: [\"Jorge Bris Moreno\", \"Eric Dapkus\", \"Brian Kwon\", \"Kangheng Liu\", \"Billy McGloin\"]\n",
        "date: last-modified\n",
        "date-format: long\n",
        "format:\n",
        "  html:\n",
        "    self-contained: true\n",
        "    toc: true\n",
        "    code-overflow: wrap\n",
        "    code-fold: true\n",
        "bibliography: ./bib.bib\n",
        "---"
      ],
      "id": "2c3ceea0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction (Brian)\n",
        "\n",
        "- What is reinforcement learning\n",
        "- What the goals of the project are/were\n",
        "  - train a model to learn air hockey\n",
        "\n",
        "# Creating The Game (Brian)\n",
        "\n",
        "- using pygame to create air hockey\n",
        "- puck and paddle class are fed into the game class which controls game logic\n",
        "- this then feeds into a main file where you can switch between modes (player v. player, player v. environment, RL v. environment)\n",
        "- we created two different simple bots to play and train against (one just went up and down and the other chased the ball around)\n",
        "  - while the one that just moved in the y direction is harder to play against, the puck can slow down on that half thus training is quicker and easier against the newer bot\n",
        "\n",
        "# Wrapping Game in Gym Environment (Kang)\n",
        "\n",
        "- gym is a toolkit for developing and comparing reinforcement learning algorithms\n",
        "- what is the environment structure\n",
        "- how is this then used for a RL algorithm\n",
        "\n",
        "# Model Selection (Jorge)\n",
        "\n",
        "- initially wanted to do a CNN model that takes downsampled grayscale frames of the game as input -> from 800x400 to 16x8\n",
        "- would take in stack of (previous) three frames so that it can detect velocity\n",
        "- while this seemed to work, the training was slow so we changed to a linear model\n",
        "- the linear model took 8 inputs - x and y for each paddle and the puck (6) and the puck's velocity in the x and y direction (2)\n",
        "- this gives the model the exact features we deem important which expedites training (besides just having less input)\n",
        "- we had numerous versions of each model (2v3 hidden layers for the linaer model) and then the cnn had different number of linear output layers\n",
        "\n",
        "# Proof of Concept (Kang)\n",
        "\n",
        "- created simplified air hockey game - kinda a mesh between air hockey and pong\n",
        "- did this directly in a custom gym environment\n",
        "- wanted to first test the environment and then train to demonstarte proof of concept\n",
        "- short videos to display results\n",
        "\n",
        "# Training Specs (Eric)\n",
        "\n",
        "We began training the reinforcement models on our personal laptops. This was sufficient at the beginning when working with the proof of concept and training a reinforcement model to play Pong. We could train the model beyond human performance overnight in 250,000 episodes. When we moved to train models on the Air Hockey personal computers fell short. \n",
        "\n",
        "The Air Hockey game is more complex than Pong. The physics of the game are more complex. Computing the new velocity of the puck after contact with a paddel is more complex, making it take longer to render the environment each step. What the model has to learn is also more complex since it has to score on a goal and not an entire side, and the shape of the padsdels adds complexity to how the model should hit the puck. These two facts made training take longer to reach the same results as compared to pong. It became clear during the early training runs that personal laptops were insuffecient to train the reenforment model to play. It was not fessible to keep a laptop running for the time required to train the model while having to use the laptop for other class work so we looked for other options. \n",
        "\n",
        "### Google Colab\n",
        "\n",
        "The first option we looked into was Google Colab Pro, a hosted Jupyter Notebook service that provides access to computing resources [-@colab]. The Pro tier provides access to faster Graphical Processing Units (GPU) and more system memory. We tried training on systems connected to L4 GPU with no additional Random Access Memory (RAM). We used the following code provided by Google to ensure the instance was connected to and using the GPU:\n",
        "\n",
        "```{{python}}\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        " print('Not connected to a GPU')\n",
        "else:\n",
        " print(gpu_info)\n",
        "```\n",
        "\n",
        "Google Colab has some preinstalled libraries for users, but it laked the gymnasium library our code depended on. After connecting the session to Google Drive we used the following code to navigate to the correct working directory, install the gymnasium library, and run our python script:\n",
        "\n",
        "```{{python}}\n",
        "#set and check working directory\n",
        "%cd /content/drive/MyDrive/neural_nets_project/models/cnn\n",
        "%pwd\n",
        "\n",
        "#install required packages fo colab\n",
        "!pip install gymnasium\n",
        "\n",
        "#run code\n",
        "!python dqn.py\n",
        "```\n",
        "We quickly moved away from Colab after we began testing on it. While the model could take advantage of the connected GPU, stepping through the game did not. Stepping through the game was the most signifficant bottleneck to training, so we moved from a paid-for-use solution to something we had on hand. \n",
        "\n",
        "### Intel NUCs\n",
        "\n",
        "We moved training to four Intel Next Unit of Computing (NUC). These are small computers messuring approximatly 4' x 4' x 2.5' and are used in many different usecases from desktopreplacement to edge computing nodes for major corperations like Chick-fil-A [-@Chambers_2023]. Our NUCs are equiped with i5-1135G7, 64GB RAM, and 500GB m.2 sold state drive. They are running Ununtu Server (22.044 LTCS). While there are many solutions to ensure the code ran continuously wee used screen to maintain persistent sessions even after we disconnect from the devices. The network's firewall is running a Virtual Private Network (VPN) service to allow us to remotely manage the servers from anywhere. \n",
        "\n",
        "While not as fast as the Google Colab instances, we could leave the systems run for days without interuption, something Colab doesn't support unless paying into a higher teir. The mini PC's each ran a model from \n",
        "\n",
        "# Training Process (Billy)\n",
        "\n",
        "- Replay memory\n",
        "- policy net\n",
        "- target net\n",
        "- selecting the action\n",
        "- optimize functoin\n",
        "- loss function\n",
        "\n",
        "# Training Results (Eric & Billy)\n",
        "\n",
        "- how models compared against each other (eric)\n",
        "- maybe a plot or two with some descriptions (eric)\n"
      ],
      "id": "6b4bcd8c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#import data\n",
        "new_ai = pd.read_csv(\"../data/new_ai/training_log.csv\")\n",
        "new_ai_750 = pd.read_csv(\"../data/new_ai_750/training_log.csv\")\n",
        "jeff = pd.read_csv(\"../data/old_ai/training_log.csv\")\n",
        "old_ai_750 = pd.read_csv(\"../data/old_ai_750/training_log.csv\")\n",
        "old_ai = pd.read_csv(\"../data/old_ai/training_log.csv\")\n",
        "final_run = pd.read_csv(\"../data/final_run/training_log.csv\")\n",
        "\n",
        "#create running sum of rewards\n",
        "new_ai['Running Total'] = new_ai['Total Reward'].cumsum()\n",
        "new_ai_750['Running Total'] = new_ai_750['Total Reward'].cumsum()\n",
        "old_ai['Running Total'] = old_ai['Total Reward'].cumsum()\n",
        "old_ai_750['Running Total'] = old_ai_750['Total Reward'].cumsum()\n",
        "final_run['Running Total'] = final_run['Total Reward'].cumsum()\n",
        "\n",
        "#add model's nick name\n",
        "new_ai['model'] = 'new_ai'\n",
        "new_ai_750['model'] = 'new_ai_750'\n",
        "old_ai['model'] = 'old_ai'\n",
        "old_ai_750['model'] = 'old_ai_750'\n",
        "final_run['model'] = 'final_run'\n",
        "\n",
        "#combine multiple dataframes into one\n",
        "df = pd.concat([new_ai, new_ai_750, old_ai, old_ai_750, final_run], ignore_index=True)\n",
        "\n",
        "#line plot showing running sum of rewards\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.set(font_scale=1.5)\n",
        "sns.lineplot(data=df, x='Episode', y='Running Total', hue='model')\n",
        "plt.title('Sum of Rewards')\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Sum of Rewards')\n",
        "plt.show()"
      ],
      "id": "33dc4a8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- how did the model perform (eric)\n",
        "- include videos at various iterations (billy)\n",
        "\n",
        "# Human v. RL - billy if accomplished\n",
        "\n",
        "- this is now a feature we have. billy or eric will train a model to make it super good and then hopefully we will be able to host this\n",
        "- if we can, maybe this part just includes a link\n",
        "\n",
        "# Conclusion (Jorge)\n",
        "\n",
        "- did we accomplish our goals? what did we learn? \n",
        "- is there anything we think could have been done better?\n",
        "- is there anything we would potentially implement in the future?"
      ],
      "id": "b789cd3d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}